package mysql

import (
	"database/sql"
	"errors"
	"io"
	"math/big"
	"time"

	codegen "bitbucket.org/codegen"

	"github.com/rs/zerolog"
	"github.com/rs/zerolog/log"
	"github.com/seambiz/seambiz/sdb"
)

// GENERATED BY CODEGEN. DO NOT EDIT.

// Tables represents a row from 'TABLES'.
type Tables struct {
	codegen.Tables
}

// new implements Bindable.new
func (ta *Tables) new() Bindable {
	return &Tables{}
}

// helper struct for common query operations.
type TablesSlice struct {
	data []*Tables
}

// append implements BindableSlice.append
func (ta *TablesSlice) append(d Bindable) {
	ta.data = append(ta.data, d.(*Tables))
}

// constant slice for all fields of the table "Tables".
// nolint[gochecknoglobals]
var tablesQueryFieldsAll = []string{"table_catalog", "table_schema", "table_name", "table_type", "engine", "version", "row_format", "table_rows", "avg_row_length", "data_length", "max_data_length", "index_length", "data_free", "auto_increment", "create_time", "update_time", "check_time", "table_collation", "checksum", "create_options", "table_comment"}

// returns fields, that should be used.
// nolint[gocyclo]
func TablesQueryFields(colSet *big.Int) []string {
	if colSet == nil {
		return tablesQueryFieldsAll
	}

	fields := []string{}
	if colSet.Bit(Tables_TableCatalog) == 1 {
		fields = append(fields, "table_catalog")
	}

	if colSet.Bit(Tables_TableSchema) == 1 {
		fields = append(fields, "table_schema")
	}

	if colSet.Bit(Tables_TableName) == 1 {
		fields = append(fields, "table_name")
	}

	if colSet.Bit(Tables_TableType) == 1 {
		fields = append(fields, "table_type")
	}

	if colSet.Bit(Tables_Engine) == 1 {
		fields = append(fields, "engine")
	}

	if colSet.Bit(Tables_Version) == 1 {
		fields = append(fields, "version")
	}

	if colSet.Bit(Tables_RowFormat) == 1 {
		fields = append(fields, "row_format")
	}

	if colSet.Bit(Tables_TableRows) == 1 {
		fields = append(fields, "table_rows")
	}

	if colSet.Bit(Tables_AvgRowLength) == 1 {
		fields = append(fields, "avg_row_length")
	}

	if colSet.Bit(Tables_DataLength) == 1 {
		fields = append(fields, "data_length")
	}

	if colSet.Bit(Tables_MaxDataLength) == 1 {
		fields = append(fields, "max_data_length")
	}

	if colSet.Bit(Tables_IndexLength) == 1 {
		fields = append(fields, "index_length")
	}

	if colSet.Bit(Tables_DataFree) == 1 {
		fields = append(fields, "data_free")
	}

	if colSet.Bit(Tables_AutoIncrement) == 1 {
		fields = append(fields, "auto_increment")
	}

	if colSet.Bit(Tables_CreateTime) == 1 {
		fields = append(fields, "create_time")
	}

	if colSet.Bit(Tables_UpdateTime) == 1 {
		fields = append(fields, "update_time")
	}

	if colSet.Bit(Tables_CheckTime) == 1 {
		fields = append(fields, "check_time")
	}

	if colSet.Bit(Tables_TableCollation) == 1 {
		fields = append(fields, "table_collation")
	}

	if colSet.Bit(Tables_Checksum) == 1 {
		fields = append(fields, "checksum")
	}

	if colSet.Bit(Tables_CreateOptions) == 1 {
		fields = append(fields, "create_options")
	}

	if colSet.Bit(Tables_TableComment) == 1 {
		fields = append(fields, "table_comment")
	}
	return fields
}

// TablesStore is used to query for 'Tables' records.
type TablesStore struct {
	Store
}

// NewTablesStore return DAO Store for Tables
func NewTablesStore(conn Execer) *TablesStore {
	ta := &TablesStore{}
	ta.db = conn
	ta.withJoin = true
	ta.joinType = sdb.LEFT
	ta.batch = 1000
	return ta
}

// WithoutJoins won't execute JOIN when querying for records.
func (ta *TablesStore) WithoutJoins() *TablesStore {
	ta.withJoin = false
	return ta
}

// Where sets local sql, that will be appended to SELECT.
func (ta *TablesStore) Where(sql string) *TablesStore {
	ta.where = sql
	return ta
}

// OrderBy sets local sql, that will be appended to SELECT.
func (ta *TablesStore) OrderBy(sql string) *TablesStore {
	ta.orderBy = sql
	return ta
}

// GroupBy sets local sql, that will be appended to SELECT.
func (ta *TablesStore) GroupBy(sql string) *TablesStore {
	ta.groupBy = sql
	return ta
}

// Limit result set size
func (ta *TablesStore) Limit(n int) *TablesStore {
	ta.limit = n
	return ta
}

// Offset used, if a limit is provided
func (ta *TablesStore) Offset(n int) *TablesStore {
	ta.offset = n
	return ta
}

// JoinType sets join statement type (Default: INNER | LEFT | RIGHT | OUTER).
func (ta *TablesStore) JoinType(jt string) *TablesStore {
	ta.joinType = jt
	return ta
}

// nolint[gocyclo]
func (ta *Tables) bind(row []sql.RawBytes, withJoin bool, colSet *big.Int, col *int) {
	if colSet == nil || colSet.Bit(Tables_TableCatalog) == 1 {
		ta.TableCatalog = sdb.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_TableSchema) == 1 {
		ta.TableSchema = sdb.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_TableName) == 1 {
		ta.TableName = sdb.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_TableType) == 1 {
		ta.TableType = sdb.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_Engine) == 1 {
		if row[*col] == nil {
			ta.Engine = nil
		} else {
			ta.Engine = new(string)
			*ta.Engine = sdb.ToString(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_Version) == 1 {
		if row[*col] == nil {
			ta.Version = nil
		} else {
			ta.Version = new(uint64)
			*ta.Version = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_RowFormat) == 1 {
		if row[*col] == nil {
			ta.RowFormat = nil
		} else {
			ta.RowFormat = new(string)
			*ta.RowFormat = sdb.ToString(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_TableRows) == 1 {
		if row[*col] == nil {
			ta.TableRows = nil
		} else {
			ta.TableRows = new(uint64)
			*ta.TableRows = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_AvgRowLength) == 1 {
		if row[*col] == nil {
			ta.AvgRowLength = nil
		} else {
			ta.AvgRowLength = new(uint64)
			*ta.AvgRowLength = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_DataLength) == 1 {
		if row[*col] == nil {
			ta.DataLength = nil
		} else {
			ta.DataLength = new(uint64)
			*ta.DataLength = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_MaxDataLength) == 1 {
		if row[*col] == nil {
			ta.MaxDataLength = nil
		} else {
			ta.MaxDataLength = new(uint64)
			*ta.MaxDataLength = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_IndexLength) == 1 {
		if row[*col] == nil {
			ta.IndexLength = nil
		} else {
			ta.IndexLength = new(uint64)
			*ta.IndexLength = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_DataFree) == 1 {
		if row[*col] == nil {
			ta.DataFree = nil
		} else {
			ta.DataFree = new(uint64)
			*ta.DataFree = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_AutoIncrement) == 1 {
		if row[*col] == nil {
			ta.AutoIncrement = nil
		} else {
			ta.AutoIncrement = new(uint64)
			*ta.AutoIncrement = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_CreateTime) == 1 {
		if row[*col] == nil {
			ta.CreateTime = nil
		} else {
			ta.CreateTime = new(time.Time)
			*ta.CreateTime = sdb.ToTime(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_UpdateTime) == 1 {
		if row[*col] == nil {
			ta.UpdateTime = nil
		} else {
			ta.UpdateTime = new(time.Time)
			*ta.UpdateTime = sdb.ToTime(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_CheckTime) == 1 {
		if row[*col] == nil {
			ta.CheckTime = nil
		} else {
			ta.CheckTime = new(time.Time)
			*ta.CheckTime = sdb.ToTime(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_TableCollation) == 1 {
		if row[*col] == nil {
			ta.TableCollation = nil
		} else {
			ta.TableCollation = new(string)
			*ta.TableCollation = sdb.ToString(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_Checksum) == 1 {
		if row[*col] == nil {
			ta.Checksum = nil
		} else {
			ta.Checksum = new(uint64)
			*ta.Checksum = sdb.ToUInt64(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_CreateOptions) == 1 {
		if row[*col] == nil {
			ta.CreateOptions = nil
		} else {
			ta.CreateOptions = new(string)
			*ta.CreateOptions = sdb.ToString(row[*col])
		}
		*col++
	}
	if colSet == nil || colSet.Bit(Tables_TableComment) == 1 {
		ta.TableComment = sdb.ToString(row[*col])
		*col++
	}
}

func (ta *TablesStore) selectStatement() *sdb.SQLStatement {
	sql := sdb.NewSQLStatement()
	sql.Append("SELECT")
	sql.Fields("", "A", TablesQueryFields(ta.colSet))
	sql.Append("FROM information_schema.TABLES A")
	if ta.where != "" {
		sql.Append("WHERE", ta.where)
	}
	if ta.groupBy != "" {
		sql.Append("GROUP BY", ta.groupBy)
	}
	if ta.orderBy != "" {
		sql.Append("ORDER BY", ta.orderBy)
	}
	if ta.limit > 0 {
		sql.AppendRaw("LIMIT ", ta.limit)
		if ta.offset > 0 {
			sql.AppendRaw(",", ta.offset)
		}
	}
	return sql
}

// QueryCustom retrieves many rows from 'information_schema.TABLES' as a slice of Tables with 1:1 joined data.
func (ta *TablesStore) QueryCustom(stmt string, args ...interface{}) ([]*codegen.Tables, error) {
	dto := &Tables{}
	data := &TablesSlice{}
	err := ta.queryCustom(data, dto, stmt, args...)
	if err != nil {
		log.Error().Err(err).Msg("querycustom")
		return nil, err
	}
	retValues := make([]*codegen.Tables, len(data.data))
	for i := range data.data {
		retValues[i] = &data.data[i].Tables
	}
	return retValues, nil
}

// One retrieves a row from 'information_schema.TABLES' as a Tables with 1:1 joined data.
func (ta *TablesStore) One(args ...interface{}) (*codegen.Tables, error) {
	data := &Tables{}

	err := ta.one(data, ta.selectStatement(), args...)
	if err != nil {
		log.Error().Err(err).Msg("query one")
		return nil, err
	}
	return &data.Tables, nil
}

// Query retrieves many rows from 'information_schema.TABLES' as a slice of Tables with 1:1 joined data.
func (ta *TablesStore) Query(args ...interface{}) ([]*codegen.Tables, error) {
	stmt := ta.selectStatement()
	return ta.QueryCustom(stmt.Query(), args...)
}

// tablesUpsertStmt helper for generating Upsert statement.
// nolint[gocyclo]
func (ta *TablesStore) tablesUpsertStmt() *sdb.UpsertStatement {
	upsert := []string{}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableCatalog) == 1 {
		upsert = append(upsert, "TABLE_CATALOG = VALUES(TABLE_CATALOG)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableSchema) == 1 {
		upsert = append(upsert, "TABLE_SCHEMA = VALUES(TABLE_SCHEMA)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableName) == 1 {
		upsert = append(upsert, "TABLE_NAME = VALUES(TABLE_NAME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableType) == 1 {
		upsert = append(upsert, "TABLE_TYPE = VALUES(TABLE_TYPE)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Engine) == 1 {
		upsert = append(upsert, "ENGINE = VALUES(ENGINE)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Version) == 1 {
		upsert = append(upsert, "VERSION = VALUES(VERSION)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_RowFormat) == 1 {
		upsert = append(upsert, "ROW_FORMAT = VALUES(ROW_FORMAT)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableRows) == 1 {
		upsert = append(upsert, "TABLE_ROWS = VALUES(TABLE_ROWS)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_AvgRowLength) == 1 {
		upsert = append(upsert, "AVG_ROW_LENGTH = VALUES(AVG_ROW_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_DataLength) == 1 {
		upsert = append(upsert, "DATA_LENGTH = VALUES(DATA_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_MaxDataLength) == 1 {
		upsert = append(upsert, "MAX_DATA_LENGTH = VALUES(MAX_DATA_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_IndexLength) == 1 {
		upsert = append(upsert, "INDEX_LENGTH = VALUES(INDEX_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_DataFree) == 1 {
		upsert = append(upsert, "DATA_FREE = VALUES(DATA_FREE)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_AutoIncrement) == 1 {
		upsert = append(upsert, "AUTO_INCREMENT = VALUES(AUTO_INCREMENT)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CreateTime) == 1 {
		upsert = append(upsert, "CREATE_TIME = VALUES(CREATE_TIME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_UpdateTime) == 1 {
		upsert = append(upsert, "UPDATE_TIME = VALUES(UPDATE_TIME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CheckTime) == 1 {
		upsert = append(upsert, "CHECK_TIME = VALUES(CHECK_TIME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableCollation) == 1 {
		upsert = append(upsert, "TABLE_COLLATION = VALUES(TABLE_COLLATION)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Checksum) == 1 {
		upsert = append(upsert, "CHECKSUM = VALUES(CHECKSUM)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CreateOptions) == 1 {
		upsert = append(upsert, "CREATE_OPTIONS = VALUES(CREATE_OPTIONS)")
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableComment) == 1 {
		upsert = append(upsert, "TABLE_COMMENT = VALUES(TABLE_COMMENT)")
	}
	sql := &sdb.UpsertStatement{}
	sql.InsertInto("information_schema.TABLES")
	sql.Columns("table_catalog", "table_schema", "table_name", "table_type", "engine", "version", "row_format", "table_rows", "avg_row_length", "data_length", "max_data_length", "index_length", "data_free", "auto_increment", "create_time", "update_time", "check_time", "table_collation", "checksum", "create_options", "table_comment")
	sql.OnDuplicateKeyUpdate(upsert)
	return sql
}

// UpsertOne inserts the Tables to the database.
func (ta *TablesStore) UpsertOne(data *codegen.Tables) (int64, error) {
	return ta.Upsert([]*codegen.Tables{data})
}

// Upsert executes upsert for array of Tables
func (ta *TablesStore) Upsert(data []*codegen.Tables) (int64, error) {
	sql := ta.tablesUpsertStmt()

	for _, d := range data {
		sql.Record(d)
	}

	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "TablesUpsert").Str("stmt", sql.String()).Msg("sql")
	}
	res, err := ta.db.Exec(sql.Query())
	if err != nil {
		log.Error().Err(err).Msg("exec")
		return -1, err
	}
	affected, err := res.RowsAffected()
	if err != nil {
		log.Error().Err(err).Msg("rowsaffected")
		return -1, err
	}

	return affected, nil
}

// Insert inserts the Tables to the database.
func (ta *TablesStore) Insert(data *codegen.Tables) error {
	var err error
	sql := sdb.NewSQLStatement()
	sql.Append("INSERT INTO information_schema.TABLES (")
	fields := TablesQueryFields(ta.colSet)
	sql.Fields("", "", fields)
	sql.Append(") VALUES (")
	for i := range fields {
		if i > 0 {
			sql.Append(",")
		}
		sql.Append("?")
	}
	sql.Append(")")

	_, err = ta.db.Exec(sql.Query(), data.TableCatalog, data.TableSchema, data.TableName, data.TableType, data.Engine, data.Version, data.RowFormat, data.TableRows, data.AvgRowLength, data.DataLength, data.MaxDataLength, data.IndexLength, data.DataFree, data.AutoIncrement, data.CreateTime, data.UpdateTime, data.CheckTime, data.TableCollation, data.Checksum, data.CreateOptions, data.TableComment)
	if err != nil {
		log.Error().Err(err).Msg("exec")
		return err
	}
	return nil
}

// Update updates the Tables in the database.
// nolint[gocyclo]
func (ta *TablesStore) Update(data *codegen.Tables) (int64, error) {
	sql := sdb.NewSQLStatement()
	var prepend string
	args := []interface{}{}
	sql.Append("UPDATE information_schema.TABLES SET")
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableCatalog) == 1 {
		sql.AppendRaw(prepend, "TABLE_CATALOG = ?")
		prepend = ","
		args = append(args, data.TableCatalog)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableSchema) == 1 {
		sql.AppendRaw(prepend, "TABLE_SCHEMA = ?")
		prepend = ","
		args = append(args, data.TableSchema)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableName) == 1 {
		sql.AppendRaw(prepend, "TABLE_NAME = ?")
		prepend = ","
		args = append(args, data.TableName)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableType) == 1 {
		sql.AppendRaw(prepend, "TABLE_TYPE = ?")
		prepend = ","
		args = append(args, data.TableType)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Engine) == 1 {
		sql.AppendRaw(prepend, "ENGINE = ?")
		prepend = ","
		args = append(args, data.Engine)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Version) == 1 {
		sql.AppendRaw(prepend, "VERSION = ?")
		prepend = ","
		args = append(args, data.Version)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_RowFormat) == 1 {
		sql.AppendRaw(prepend, "ROW_FORMAT = ?")
		prepend = ","
		args = append(args, data.RowFormat)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableRows) == 1 {
		sql.AppendRaw(prepend, "TABLE_ROWS = ?")
		prepend = ","
		args = append(args, data.TableRows)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_AvgRowLength) == 1 {
		sql.AppendRaw(prepend, "AVG_ROW_LENGTH = ?")
		prepend = ","
		args = append(args, data.AvgRowLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_DataLength) == 1 {
		sql.AppendRaw(prepend, "DATA_LENGTH = ?")
		prepend = ","
		args = append(args, data.DataLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_MaxDataLength) == 1 {
		sql.AppendRaw(prepend, "MAX_DATA_LENGTH = ?")
		prepend = ","
		args = append(args, data.MaxDataLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_IndexLength) == 1 {
		sql.AppendRaw(prepend, "INDEX_LENGTH = ?")
		prepend = ","
		args = append(args, data.IndexLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_DataFree) == 1 {
		sql.AppendRaw(prepend, "DATA_FREE = ?")
		prepend = ","
		args = append(args, data.DataFree)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_AutoIncrement) == 1 {
		sql.AppendRaw(prepend, "AUTO_INCREMENT = ?")
		prepend = ","
		args = append(args, data.AutoIncrement)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CreateTime) == 1 {
		sql.AppendRaw(prepend, "CREATE_TIME = ?")
		prepend = ","
		args = append(args, data.CreateTime)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_UpdateTime) == 1 {
		sql.AppendRaw(prepend, "UPDATE_TIME = ?")
		prepend = ","
		args = append(args, data.UpdateTime)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CheckTime) == 1 {
		sql.AppendRaw(prepend, "CHECK_TIME = ?")
		prepend = ","
		args = append(args, data.CheckTime)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableCollation) == 1 {
		sql.AppendRaw(prepend, "TABLE_COLLATION = ?")
		prepend = ","
		args = append(args, data.TableCollation)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Checksum) == 1 {
		sql.AppendRaw(prepend, "CHECKSUM = ?")
		prepend = ","
		args = append(args, data.Checksum)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CreateOptions) == 1 {
		sql.AppendRaw(prepend, "CREATE_OPTIONS = ?")
		prepend = ","
		args = append(args, data.CreateOptions)
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableComment) == 1 {
		sql.AppendRaw(prepend, "TABLE_COMMENT = ?")
		args = append(args, data.TableComment)
	}
	sql.Append(" WHERE ")
	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "information_schema.TABLES.Update").Str("stmt", sql.String()).Interface("args", args).Msg("sql")
	}
	res, err := ta.db.Exec(sql.Query(), args...)
	if err != nil {
		log.Error().Err(err).Msg("exec")
		return 0, err
	}
	return res.RowsAffected()
}

// Delete deletes the Tables from the database.
func (ta *TablesStore) Delete(data *codegen.Tables) error {
	var err error

	sql := sdb.NewSQLStatement()
	sql.Append("DELETE FROM information_schema.TABLES WHERE")
	sql.Append("")

	_, err = ta.db.Exec(sql.Query())
	if err != nil {
		log.Error().Err(err).Msg("exec")
	}

	return err
}

// DeleteByQuery uses a where condition to delete entries.
func (ta *TablesStore) DeleteByQuery(args ...interface{}) error {
	var err error
	sql := sdb.NewSQLStatement()
	sql.Append("DELETE FROM information_schema.TABLES")
	if ta.where == "" {
		return errors.New("no where condition set")
	}
	sql.Append("WHERE", ta.where)
	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "information_schema.TABLES.DeleteByQuery").Str("stmt", sql.String()).Interface("args", args).Msg("sql")
	}

	_, err = ta.db.Exec(sql.Query(), args...)
	if err != nil {
		log.Error().Err(err).Msg("exec")
	}

	return err
}

// Truncate deletes all rows from Tables.
func (ta *TablesStore) Truncate() error {
	sql := sdb.NewSQLStatement()
	sql.Append("TRUNCATE information_schema.TABLES")
	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "information_schema.TABLES.Truncate").Str("stmt", sql.String()).Msg("sql")
	}
	_, err := ta.db.Exec(sql.Query())
	if err != nil {
		log.Error().Err(err).Msg("exec")
	}
	return err
}

// ToJSON writes a single object to the buffer.
// nolint[gocylco]
func (ta *TablesStore) ToJSON(t *sdb.JsonBuffer, data *Tables) {
	prepend := "{"
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableCatalog) == 1 {
		t.JS(prepend, "table_catalog", data.TableCatalog)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableSchema) == 1 {
		t.JS(prepend, "table_schema", data.TableSchema)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableName) == 1 {
		t.JS(prepend, "table_name", data.TableName)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableType) == 1 {
		t.JS(prepend, "table_type", data.TableType)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Engine) == 1 {
		t.JS(prepend, "engine", *data.Engine)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Version) == 1 {
		t.JD64u(prepend, "version", *data.Version)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_RowFormat) == 1 {
		t.JS(prepend, "row_format", *data.RowFormat)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableRows) == 1 {
		t.JD64u(prepend, "table_rows", *data.TableRows)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_AvgRowLength) == 1 {
		t.JD64u(prepend, "avg_row_length", *data.AvgRowLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_DataLength) == 1 {
		t.JD64u(prepend, "data_length", *data.DataLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_MaxDataLength) == 1 {
		t.JD64u(prepend, "max_data_length", *data.MaxDataLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_IndexLength) == 1 {
		t.JD64u(prepend, "index_length", *data.IndexLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_DataFree) == 1 {
		t.JD64u(prepend, "data_free", *data.DataFree)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_AutoIncrement) == 1 {
		t.JD64u(prepend, "auto_increment", *data.AutoIncrement)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CreateTime) == 1 {
		t.JT(prepend, "create_time", *data.CreateTime)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_UpdateTime) == 1 {
		t.JT(prepend, "update_time", *data.UpdateTime)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CheckTime) == 1 {
		t.JT(prepend, "check_time", *data.CheckTime)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableCollation) == 1 {
		t.JS(prepend, "table_collation", *data.TableCollation)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_Checksum) == 1 {
		t.JD64u(prepend, "checksum", *data.Checksum)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_CreateOptions) == 1 {
		t.JS(prepend, "create_options", *data.CreateOptions)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(Tables_TableComment) == 1 {
		t.JS(prepend, "table_comment", data.TableComment)
	}
	t.S(`}`)
}

// ToJSONArray writes a slice to the named array.
func (ta *TablesStore) ToJSONArray(w io.Writer, data []*Tables, name string) {
	t := sdb.NewJsonBuffer()
	t.SS(`{"`, name, `":[`)
	for i := range data {
		if i > 0 {
			t.S(",")
		}
		ta.ToJSON(t, data[i])
	}

	t.S("]}")
	_, err := w.Write(t.Bytes())
	if err != nil {
		panic(err)
	}
}

// ^^ END OF GENERATED BY CODEGEN. DO NOT EDIT. ^^
