// Package db contains the types for schema 'information_schema'.
package models

import (
	"database/sql"
	"io"
	"math/big"
	"time"

	"bitbucket.org/codegen/convert"
	"bitbucket.org/seambiz/buffer"
	"bitbucket.org/seambiz/sdb"
	"github.com/rs/zerolog"
	"github.com/rs/zerolog/log"
)

// GENERATED BY CODEGEN. DO NOT EDIT.
// constant slice for all fields of the table.
// nolint[gochecknoglobals]
var tablesQueryFieldsAll = []string{"table_catalog", "table_schema", "table_name", "table_type", "engine", "version", "row_format", "table_rows", "avg_row_length", "data_length", "max_data_length", "index_length", "data_free", "auto_increment", "create_time", "update_time", "check_time", "table_collation", "checksum", "create_options", "table_comment"}

// returns fields, that should be used.
// nolint[gocyclo]
func TablesQueryFields(colSet *big.Int) []string {
	if colSet == nil {
		return tablesQueryFieldsAll
	}

	fields := []string{}
	if colSet.Bit(TablesTableCatalog) == 1 {
		fields = append(fields, "table_catalog")
	}
	if colSet.Bit(TablesTableSchema) == 1 {
		fields = append(fields, "table_schema")
	}
	if colSet.Bit(TablesTableName) == 1 {
		fields = append(fields, "table_name")
	}
	if colSet.Bit(TablesTableType) == 1 {
		fields = append(fields, "table_type")
	}
	if colSet.Bit(TablesEngine) == 1 {
		fields = append(fields, "engine")
	}
	if colSet.Bit(TablesVersion) == 1 {
		fields = append(fields, "version")
	}
	if colSet.Bit(TablesRowFormat) == 1 {
		fields = append(fields, "row_format")
	}
	if colSet.Bit(TablesTableRows) == 1 {
		fields = append(fields, "table_rows")
	}
	if colSet.Bit(TablesAvgRowLength) == 1 {
		fields = append(fields, "avg_row_length")
	}
	if colSet.Bit(TablesDataLength) == 1 {
		fields = append(fields, "data_length")
	}
	if colSet.Bit(TablesMaxDataLength) == 1 {
		fields = append(fields, "max_data_length")
	}
	if colSet.Bit(TablesIndexLength) == 1 {
		fields = append(fields, "index_length")
	}
	if colSet.Bit(TablesDataFree) == 1 {
		fields = append(fields, "data_free")
	}
	if colSet.Bit(TablesAutoIncrement) == 1 {
		fields = append(fields, "auto_increment")
	}
	if colSet.Bit(TablesCreateTime) == 1 {
		fields = append(fields, "create_time")
	}
	if colSet.Bit(TablesUpdateTime) == 1 {
		fields = append(fields, "update_time")
	}
	if colSet.Bit(TablesCheckTime) == 1 {
		fields = append(fields, "check_time")
	}
	if colSet.Bit(TablesTableCollation) == 1 {
		fields = append(fields, "table_collation")
	}
	if colSet.Bit(TablesChecksum) == 1 {
		fields = append(fields, "checksum")
	}
	if colSet.Bit(TablesCreateOptions) == 1 {
		fields = append(fields, "create_options")
	}
	if colSet.Bit(TablesTableComment) == 1 {
		fields = append(fields, "table_comment")
	}
	return fields
}

// Tables represents a row from 'information_schema.TABLES'.
type Tables struct {
	TableCatalog   string    `json:"TABLE_CATALOG" db:"table_catalog"`
	TableSchema    string    `json:"TABLE_SCHEMA" db:"table_schema"`
	TableName      string    `json:"TABLE_NAME" db:"table_name"`
	TableType      string    `json:"TABLE_TYPE" db:"table_type"`
	Engine         string    `json:"ENGINE" db:"engine"`
	Version        uint64    `json:"VERSION" db:"version"`
	RowFormat      string    `json:"ROW_FORMAT" db:"row_format"`
	TableRows      uint64    `json:"TABLE_ROWS" db:"table_rows"`
	AvgRowLength   uint64    `json:"AVG_ROW_LENGTH" db:"avg_row_length"`
	DataLength     uint64    `json:"DATA_LENGTH" db:"data_length"`
	MaxDataLength  uint64    `json:"MAX_DATA_LENGTH" db:"max_data_length"`
	IndexLength    uint64    `json:"INDEX_LENGTH" db:"index_length"`
	DataFree       uint64    `json:"DATA_FREE" db:"data_free"`
	AutoIncrement  uint64    `json:"AUTO_INCREMENT" db:"auto_increment"`
	CreateTime     time.Time `json:"CREATE_TIME" db:"create_time"`
	UpdateTime     time.Time `json:"UPDATE_TIME" db:"update_time"`
	CheckTime      time.Time `json:"CHECK_TIME" db:"check_time"`
	TableCollation string    `json:"TABLE_COLLATION" db:"table_collation"`
	Checksum       uint64    `json:"CHECKSUM" db:"checksum"`
	CreateOptions  string    `json:"CREATE_OPTIONS" db:"create_options"`
	TableComment   string    `json:"TABLE_COMMENT" db:"table_comment"`
}

// new implements DTO.new
func (ta *Tables) new() DTO {
	return &Tables{}
}

// helper struct for common query operations.
type TablesSlice struct {
	data []*Tables
}

// append implements DTOSlice.append
func (ta *TablesSlice) append(d DTO) {
	ta.data = append(ta.data, d.(*Tables))
}

// Columns to be used for various statements.
func (ta *TablesStore) Columns(cols ...int) *TablesStore {
	ta.colSet = big.NewInt(0)
	for _, col := range cols {
		ta.colSet.SetBit(ta.colSet, col, 1)
	}
	return ta
}

// IsEmpty checks if primary key fields are zero.
func (ta *Tables) IsEmpty() bool {
	return true
}

// TablesStore is used to query for 'Tables' records.
type TablesStore struct {
	Store
}

// NewTablesStore return DAO Store for Tables
func NewTablesStore(conn *sql.DB) *TablesStore {
	ta := &TablesStore{}
	ta.db = conn
	ta.withJoin = true
	ta.joinType = sdb.LEFT
	ta.batch = 1000
	return ta
}

// WithoutJoins won't execute JOIN when querying for records.
func (ta *TablesStore) WithoutJoins() *TablesStore {
	ta.withJoin = false
	return ta
}

// Where sets local sql, that will be appended to SELECT.
func (ta *TablesStore) Where(sql string) *TablesStore {
	ta.where = sql
	return ta
}

// OrderBy sets local sql, that will be appended to SELECT.
func (ta *TablesStore) OrderBy(sql string) *TablesStore {
	ta.orderBy = sql
	return ta
}

// GroupBy sets local sql, that will be appended to SELECT.
func (ta *TablesStore) GroupBy(sql string) *TablesStore {
	ta.groupBy = sql
	return ta
}

// Limit result set size
func (ta *TablesStore) Limit(n int) *TablesStore {
	ta.limit = n
	return ta
}

// Offset used, if a limit is provided
func (ta *TablesStore) Offset(n int) *TablesStore {
	ta.offset = n
	return ta
}

// JoinType sets join statement type (Default: INNER | LEFT | RIGHT | OUTER).
func (ta *TablesStore) JoinType(jt string) *TablesStore {
	ta.joinType = jt
	return ta
}

// nolint[gocyclo]
func (ta *Tables) bind(row []sql.RawBytes, withJoin bool, colSet *big.Int, col *int) {
	if colSet == nil || colSet.Bit(TablesTableCatalog) == 1 {
		ta.TableCatalog = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesTableSchema) == 1 {
		ta.TableSchema = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesTableName) == 1 {
		ta.TableName = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesTableType) == 1 {
		ta.TableType = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesEngine) == 1 {
		ta.Engine = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesVersion) == 1 {
		ta.Version = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesRowFormat) == 1 {
		ta.RowFormat = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesTableRows) == 1 {
		ta.TableRows = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesAvgRowLength) == 1 {
		ta.AvgRowLength = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesDataLength) == 1 {
		ta.DataLength = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesMaxDataLength) == 1 {
		ta.MaxDataLength = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesIndexLength) == 1 {
		ta.IndexLength = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesDataFree) == 1 {
		ta.DataFree = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesAutoIncrement) == 1 {
		ta.AutoIncrement = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesCreateTime) == 1 {
		ta.CreateTime = convert.ToTime(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesUpdateTime) == 1 {
		ta.UpdateTime = convert.ToTime(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesCheckTime) == 1 {
		ta.CheckTime = convert.ToTime(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesTableCollation) == 1 {
		ta.TableCollation = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesChecksum) == 1 {
		ta.Checksum = convert.ToUInt64(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesCreateOptions) == 1 {
		ta.CreateOptions = convert.ToString(row[*col])
		*col++
	}
	if colSet == nil || colSet.Bit(TablesTableComment) == 1 {
		ta.TableComment = convert.ToString(row[*col])
		*col++
	}
}
func (ta *TablesStore) selectStatement() *sdb.SQLStatement {
	sql := sdb.NewSQLStatement()
	sql.Append("SELECT")
	sql.Fields("", "A", TablesQueryFields(ta.colSet))
	sql.Append("FROM information_schema.TABLES A")
	if ta.where != "" {
		sql.Append("WHERE", ta.where)
	}
	if ta.groupBy != "" {
		sql.Append("GROUP BY", ta.groupBy)
	}
	if ta.orderBy != "" {
		sql.Append("ORDER BY", ta.orderBy)
	}
	if ta.limit > 0 {
		sql.AppendRaw("LIMIT ", ta.limit)
		if ta.offset > 0 {
			sql.AppendRaw(",", ta.offset)
		}
	}
	return sql
}

// One retrieves a row from 'information_schema.TABLES' as a Tables with possible joined data.
func (ta *TablesStore) One(args ...interface{}) (*Tables, error) {
	data := &Tables{}

	err := ta.one(data, ta.selectStatement(), args...)
	if err != nil {
		log.Error().Err(err).Msg("query one")
		return nil, err
	}
	return data, nil
}

// Query retrieves many rows from 'information_schema.TABLES' as a slice of Tables with possible joined data.
func (ta *TablesStore) Query(args ...interface{}) ([]*Tables, error) {
	stmt := ta.selectStatement()
	return ta.QueryCustom(stmt.Query(), args...)
}

// QueryCustom retrieves many rows from 'information_schema.TABLES' as a slice of Tables with possible joined data.
func (ta *TablesStore) QueryCustom(stmt string, args ...interface{}) ([]*Tables, error) {
	dto := &Tables{}
	data := &TablesSlice{}
	err := ta.queryCustom(data, dto, stmt, args...)
	if err != nil {
		log.Error().Err(err).Msg("querycustom")
		return nil, err
	}
	return data.data, nil
}

// tablesUpsertStmt helper for generating Upserts general statement
// nolint[gocyclo]
func (ta *TablesStore) tablesUpsertStmt() *sdb.UpsertStatement {
	upsert := []string{}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableCatalog) == 1 {
		upsert = append(upsert, "TABLE_CATALOG = VALUES(TABLE_CATALOG)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableSchema) == 1 {
		upsert = append(upsert, "TABLE_SCHEMA = VALUES(TABLE_SCHEMA)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableName) == 1 {
		upsert = append(upsert, "TABLE_NAME = VALUES(TABLE_NAME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableType) == 1 {
		upsert = append(upsert, "TABLE_TYPE = VALUES(TABLE_TYPE)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesEngine) == 1 {
		upsert = append(upsert, "ENGINE = VALUES(ENGINE)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesVersion) == 1 {
		upsert = append(upsert, "VERSION = VALUES(VERSION)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesRowFormat) == 1 {
		upsert = append(upsert, "ROW_FORMAT = VALUES(ROW_FORMAT)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableRows) == 1 {
		upsert = append(upsert, "TABLE_ROWS = VALUES(TABLE_ROWS)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesAvgRowLength) == 1 {
		upsert = append(upsert, "AVG_ROW_LENGTH = VALUES(AVG_ROW_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesDataLength) == 1 {
		upsert = append(upsert, "DATA_LENGTH = VALUES(DATA_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesMaxDataLength) == 1 {
		upsert = append(upsert, "MAX_DATA_LENGTH = VALUES(MAX_DATA_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesIndexLength) == 1 {
		upsert = append(upsert, "INDEX_LENGTH = VALUES(INDEX_LENGTH)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesDataFree) == 1 {
		upsert = append(upsert, "DATA_FREE = VALUES(DATA_FREE)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesAutoIncrement) == 1 {
		upsert = append(upsert, "AUTO_INCREMENT = VALUES(AUTO_INCREMENT)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCreateTime) == 1 {
		upsert = append(upsert, "CREATE_TIME = VALUES(CREATE_TIME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesUpdateTime) == 1 {
		upsert = append(upsert, "UPDATE_TIME = VALUES(UPDATE_TIME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCheckTime) == 1 {
		upsert = append(upsert, "CHECK_TIME = VALUES(CHECK_TIME)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableCollation) == 1 {
		upsert = append(upsert, "TABLE_COLLATION = VALUES(TABLE_COLLATION)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesChecksum) == 1 {
		upsert = append(upsert, "CHECKSUM = VALUES(CHECKSUM)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCreateOptions) == 1 {
		upsert = append(upsert, "CREATE_OPTIONS = VALUES(CREATE_OPTIONS)")
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableComment) == 1 {
		upsert = append(upsert, "TABLE_COMMENT = VALUES(TABLE_COMMENT)")
	}
	sql := &sdb.UpsertStatement{}
	sql.InsertInto("information_schema.TABLES")
	sql.Columns("table_catalog", "table_schema", "table_name", "table_type", "engine", "version", "row_format", "table_rows", "avg_row_length", "data_length", "max_data_length", "index_length", "data_free", "auto_increment", "create_time", "update_time", "check_time", "table_collation", "checksum", "create_options", "table_comment")
	sql.OnDuplicateKeyUpdate(upsert)
	return sql
}

// UpsertOne inserts the Tables to the database.
func (ta *TablesStore) UpsertOne(data *Tables) (int64, error) {
	return ta.Upsert([]*Tables{data})
}

// Upsert executes upsert for array of Tables
func (ta *TablesStore) Upsert(data []*Tables) (int64, error) {
	sql := ta.tablesUpsertStmt()

	for _, d := range data {
		sql.Record(d)
	}

	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "TablesUpsert").Str("stmt", sql.String()).Msg("sql")
	}
	res, err := ta.db.Exec(sql.Query())
	if err != nil {
		log.Error().Err(err).Msg("exec")
		return -1, err
	}
	affected, err := res.RowsAffected()
	if err != nil {
		log.Error().Err(err).Msg("rowsaffected")
		return -1, err
	}

	return affected, nil
}

// Insert inserts the Tables to the database.
func (ta *TablesStore) Insert(data *Tables) error {
	var err error
	sql := sdb.NewSQLStatement()
	sql.Append("INSERT INTO information_schema.TABLES (")
	fields := TablesQueryFields(ta.colSet)
	sql.Fields("", "", fields)
	sql.Append(") VALUES (")
	for i := range fields {
		if i > 0 {
			sql.Append(",")
		}
		sql.Append("?")
	}
	sql.Append(")")

	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "information_schema.TABLES.Insert").Str("stmt", sql.String()).Str("TableCatalog", data.TableCatalog).Str("TableSchema", data.TableSchema).Str("TableName", data.TableName).Str("TableType", data.TableType).Str("Engine", data.Engine).Uint64("Version", data.Version).Str("RowFormat", data.RowFormat).Uint64("TableRows", data.TableRows).Uint64("AvgRowLength", data.AvgRowLength).Uint64("DataLength", data.DataLength).Uint64("MaxDataLength", data.MaxDataLength).Uint64("IndexLength", data.IndexLength).Uint64("DataFree", data.DataFree).Uint64("AutoIncrement", data.AutoIncrement).Time("CreateTime", data.CreateTime).Time("UpdateTime", data.UpdateTime).Time("CheckTime", data.CheckTime).Str("TableCollation", data.TableCollation).Uint64("Checksum", data.Checksum).Str("CreateOptions", data.CreateOptions).Str("TableComment", data.TableComment).Msg("sql")
	}
	_, err = ta.db.Exec(sql.Query(), data.TableCatalog, data.TableSchema, data.TableName, data.TableType, data.Engine, data.Version, data.RowFormat, data.TableRows, data.AvgRowLength, data.DataLength, data.MaxDataLength, data.IndexLength, data.DataFree, data.AutoIncrement, data.CreateTime, data.UpdateTime, data.CheckTime, data.TableCollation, data.Checksum, data.CreateOptions, data.TableComment)
	if err != nil {
		log.Error().Err(err).Msg("exec")
		return err
	}
	return nil
}

// Update updates the Tables in the database.
// nolint[gocyclo]
func (ta *TablesStore) Update(data *Tables) (int64, error) {
	sql := sdb.NewSQLStatement()
	var prepend string
	args := []interface{}{}
	sql.Append("UPDATE information_schema.TABLES SET")
	if ta.colSet == nil || ta.colSet.Bit(TablesTableCatalog) == 1 {
		sql.AppendRaw(prepend, "TABLE_CATALOG = ?")
		prepend = ","
		args = append(args, data.TableCatalog)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableSchema) == 1 {
		sql.AppendRaw(prepend, "TABLE_SCHEMA = ?")
		prepend = ","
		args = append(args, data.TableSchema)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableName) == 1 {
		sql.AppendRaw(prepend, "TABLE_NAME = ?")
		prepend = ","
		args = append(args, data.TableName)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableType) == 1 {
		sql.AppendRaw(prepend, "TABLE_TYPE = ?")
		prepend = ","
		args = append(args, data.TableType)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesEngine) == 1 {
		sql.AppendRaw(prepend, "ENGINE = ?")
		prepend = ","
		args = append(args, data.Engine)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesVersion) == 1 {
		sql.AppendRaw(prepend, "VERSION = ?")
		prepend = ","
		args = append(args, data.Version)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesRowFormat) == 1 {
		sql.AppendRaw(prepend, "ROW_FORMAT = ?")
		prepend = ","
		args = append(args, data.RowFormat)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableRows) == 1 {
		sql.AppendRaw(prepend, "TABLE_ROWS = ?")
		prepend = ","
		args = append(args, data.TableRows)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesAvgRowLength) == 1 {
		sql.AppendRaw(prepend, "AVG_ROW_LENGTH = ?")
		prepend = ","
		args = append(args, data.AvgRowLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesDataLength) == 1 {
		sql.AppendRaw(prepend, "DATA_LENGTH = ?")
		prepend = ","
		args = append(args, data.DataLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesMaxDataLength) == 1 {
		sql.AppendRaw(prepend, "MAX_DATA_LENGTH = ?")
		prepend = ","
		args = append(args, data.MaxDataLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesIndexLength) == 1 {
		sql.AppendRaw(prepend, "INDEX_LENGTH = ?")
		prepend = ","
		args = append(args, data.IndexLength)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesDataFree) == 1 {
		sql.AppendRaw(prepend, "DATA_FREE = ?")
		prepend = ","
		args = append(args, data.DataFree)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesAutoIncrement) == 1 {
		sql.AppendRaw(prepend, "AUTO_INCREMENT = ?")
		prepend = ","
		args = append(args, data.AutoIncrement)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCreateTime) == 1 {
		sql.AppendRaw(prepend, "CREATE_TIME = ?")
		prepend = ","
		args = append(args, data.CreateTime)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesUpdateTime) == 1 {
		sql.AppendRaw(prepend, "UPDATE_TIME = ?")
		prepend = ","
		args = append(args, data.UpdateTime)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCheckTime) == 1 {
		sql.AppendRaw(prepend, "CHECK_TIME = ?")
		prepend = ","
		args = append(args, data.CheckTime)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableCollation) == 1 {
		sql.AppendRaw(prepend, "TABLE_COLLATION = ?")
		prepend = ","
		args = append(args, data.TableCollation)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesChecksum) == 1 {
		sql.AppendRaw(prepend, "CHECKSUM = ?")
		prepend = ","
		args = append(args, data.Checksum)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCreateOptions) == 1 {
		sql.AppendRaw(prepend, "CREATE_OPTIONS = ?")
		prepend = ","
		args = append(args, data.CreateOptions)
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableComment) == 1 {
		sql.AppendRaw(prepend, "TABLE_COMMENT = ?")
		args = append(args, data.TableComment)
	}
	sql.Append(" WHERE ")
	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "information_schema.TABLES.Update").Str("stmt", sql.String()).Interface("args", args).Msg("sql")
	}
	res, err :=
		ta.db.Exec(sql.Query(), args...)
	if err != nil {
		log.Error().Err(err).Msg("exec")
		return 0, err
	}
	return res.RowsAffected()
}

// Truncate deletes all rows from Tables.
func (ta *TablesStore) Truncate() error {
	sql := sdb.NewSQLStatement()
	sql.Append("TRUNCATE information_schema.TABLES")
	if zerolog.GlobalLevel() == zerolog.DebugLevel {
		log.Debug().Str("fn", "information_schema.TABLES.Truncate").Str("stmt", sql.String()).Msg("sql")
	}
	_, err := ta.db.Exec(sql.Query())
	if err != nil {
		log.Error().Err(err).Msg("exec")
	}
	return err
}

// ToJSON writes a single object to the buffer.
// nolint[gocylco]
func (ta *TablesStore) ToJSON(t *buffer.TemplateBuffer, data *Tables) {
	prepend := "{"
	if ta.colSet == nil || ta.colSet.Bit(TablesTableCatalog) == 1 {
		t.JS(prepend, "table_catalog", data.TableCatalog)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableSchema) == 1 {
		t.JS(prepend, "table_schema", data.TableSchema)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableName) == 1 {
		t.JS(prepend, "table_name", data.TableName)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableType) == 1 {
		t.JS(prepend, "table_type", data.TableType)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesEngine) == 1 {
		t.JS(prepend, "engine", data.Engine)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesVersion) == 1 {
		t.JD64u(prepend, "version", data.Version)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesRowFormat) == 1 {
		t.JS(prepend, "row_format", data.RowFormat)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableRows) == 1 {
		t.JD64u(prepend, "table_rows", data.TableRows)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesAvgRowLength) == 1 {
		t.JD64u(prepend, "avg_row_length", data.AvgRowLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesDataLength) == 1 {
		t.JD64u(prepend, "data_length", data.DataLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesMaxDataLength) == 1 {
		t.JD64u(prepend, "max_data_length", data.MaxDataLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesIndexLength) == 1 {
		t.JD64u(prepend, "index_length", data.IndexLength)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesDataFree) == 1 {
		t.JD64u(prepend, "data_free", data.DataFree)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesAutoIncrement) == 1 {
		t.JD64u(prepend, "auto_increment", data.AutoIncrement)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCreateTime) == 1 {
		t.JT(prepend, "create_time", data.CreateTime)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesUpdateTime) == 1 {
		t.JT(prepend, "update_time", data.UpdateTime)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCheckTime) == 1 {
		t.JT(prepend, "check_time", data.CheckTime)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableCollation) == 1 {
		t.JS(prepend, "table_collation", data.TableCollation)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesChecksum) == 1 {
		t.JD64u(prepend, "checksum", data.Checksum)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesCreateOptions) == 1 {
		t.JS(prepend, "create_options", data.CreateOptions)
		prepend = ","
	}
	if ta.colSet == nil || ta.colSet.Bit(TablesTableComment) == 1 {
		t.JS(prepend, "table_comment", data.TableComment)
	}
	t.S(`}`)
}

// ToJSONArray writes a slice to the named array.
func (ta *TablesStore) ToJSONArray(w io.Writer, data []*Tables, name string) {
	t := buffer.NewTemplateBuffer()
	t.SS(`{"`, name, `":[`)
	for i := range data {
		if i > 0 {
			t.S(",")
		}
		ta.ToJSON(t, data[i])
	}

	t.S("]}")
	_, err := w.Write(t.Bytes())
	if err != nil {
		panic(err)
	}
}

// ^^ END OF GENERATED BY CODEGEN. DO NOT EDIT. ^^
